{"cells":[{"cell_type":"markdown","id":"80a6e8e9","metadata":{"id":"80a6e8e9"},"source":["4-1 計算環境:  Google Colaboratory\n","\n","メリット\n","    - 環境構築に手間がかからない  \n","    - ライブラリが入っている\n","    - GPU計算が簡単\n","    \n","\n","利用するライブラリ\n","\n","- transformaers  \n","    ニューラル言語モデルのライブラリ  \n","- Fugashi  \n","    MeCabのPython用ライブラリ  \n","- ipadic  \n","    MeCabで形態素解析を行う際に用いる辞書  \n","    \n","Colaboratory では, !の後にコマンドを書くとコマンド実行できる\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["!pip install transformers fugashi ipadic"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zUUZ0sG7MKC","executionInfo":{"status":"ok","timestamp":1660557339880,"user_tz":-540,"elapsed":18797,"user":{"displayName":"a kaya","userId":"07654136242285001252"}},"outputId":"2a5915f7-7b36-41d2-e326-434be35dc080"},"id":"0zUUZ0sG7MKC","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 36.4 MB/s \n","\u001b[?25hCollecting fugashi\n","  Downloading fugashi-1.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (568 kB)\n","\u001b[K     |████████████████████████████████| 568 kB 72.4 MB/s \n","\u001b[?25hCollecting ipadic\n","  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n","\u001b[K     |████████████████████████████████| 13.4 MB 30.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 11.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 59.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 67.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Building wheels for collected packages: ipadic\n","  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556723 sha256=47cadb74db9b4e6976dccad2a99fd020d4158d2f2ba707166c313cc9e01e139c\n","  Stored in directory: /root/.cache/pip/wheels/33/8b/99/cf0d27191876637cd3639a560f93aa982d7855ce826c94348b\n","Successfully built ipadic\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, ipadic, fugashi\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed fugashi-1.1.2 huggingface-hub-0.8.1 ipadic-1.0.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"code","execution_count":6,"id":"bd8e0c23","metadata":{"id":"bd8e0c23","executionInfo":{"status":"ok","timestamp":1660558423396,"user_tz":-540,"elapsed":3,"user":{"displayName":"a kaya","userId":"07654136242285001252"}}},"outputs":[],"source":["import torch \n","from transformers import BertJapaneseTokenizer, BertModel\n"]},{"cell_type":"markdown","id":"931120a4","metadata":{"id":"931120a4"},"source":["- Transformers  \n","    - Huggingface 社が提供しているN言語モデルのOSS  \n","    - cl-touhoku/bert-base-japanese-whole-word-masking  \n","        - 東北大学がWikipediaの日本語記事データを用いて学習したモデル  \n","        \n","    - 処理手順  \n","    1. トークナイザを用いて,文章をトークン化\n","    2. 処理したデータをBERTに入力し,出力を得る  \n","    \n","- トークナイザ  \n","    文章をトークンに分割し,BERTに入力できる形に変換."]},{"cell_type":"code","execution_count":7,"id":"a6e804e3","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["a5dd80beb9b24b0fa03fdef858937a9c","99e26d43f47b4573bcf69c61b05cb8ca","25b08c8b80cc4ab09beaef6ea85a6c50","00924c4df9c64a6098012fc8d2c875d3","62870f7f045c46ebaed551effe69e22a","6093022ac621423bbcf06beb413c3761","42a16b06b0154b42b7c4d00345e9cc33","6fb646e2ef5740a5b337590a8779b697","4e2f916054d140e288a8ebf921cea1a2","f453b394e6884ee2bd3e79bf21f66d2e","d9484351b4af4d10b7eb558461a1edb9","2e96e608c4f9420ea89c64c8ab526542","eaecc0960283409999a8b2346317884b","6fec5d77d9ff43e5bc66e6d4414d20e7","16f8e28a7de74322a3700c0b4e152c23","42dd4e35bff94ca7af5605145ab0302e","99117651d5b14c4281697752cd5bf802","91a81747e8514089b9d436144b9dfce2","0544859bde5c4d0e85a9fd88ca6c0149","600668237b3e4112904f09cb783d76dd","c88616557ffe45c194c25682fb763e87","d11a78602be6413c8d3f1ae4e7177a2c"]},"id":"a6e804e3","executionInfo":{"status":"ok","timestamp":1660558434130,"user_tz":-540,"elapsed":7682,"user":{"displayName":"a kaya","userId":"07654136242285001252"}},"outputId":"7644df74-5206-446e-cdbc-f37c69ba4d1d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading vocab.txt:   0%|          | 0.00/252k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5dd80beb9b24b0fa03fdef858937a9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/110 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e96e608c4f9420ea89c64c8ab526542"}},"metadata":{}}],"source":["model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n","# 学習済みのトークナイザをロード\n","tokenizer = BertJapaneseTokenizer.from_pretrained(model_name)"]},{"cell_type":"markdown","id":"2fd51356","metadata":{"id":"2fd51356"},"source":["内部では, \n","1. MeCabで単語分割  \n","2. WOrdPieceでトークン化  \n","している."]},{"cell_type":"code","execution_count":8,"id":"51226ad2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51226ad2","executionInfo":{"status":"ok","timestamp":1660558438122,"user_tz":-540,"elapsed":457,"user":{"displayName":"a kaya","userId":"07654136242285001252"}},"outputId":"e67b237d-9978-4186-b2d7-19b6ac9e5f1e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['明日', 'は', '自然', '言語', '処理', 'の', '勉強', 'を', 'しよ', 'う', '.']"]},"metadata":{},"execution_count":8}],"source":["#トークン化してみる\n","tokenizer.tokenize('明日は自然言語処理の勉強をしよう.')"]},{"cell_type":"code","execution_count":9,"id":"0e029afa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0e029afa","executionInfo":{"status":"ok","timestamp":1660558441197,"user_tz":-540,"elapsed":6,"user":{"displayName":"a kaya","userId":"07654136242285001252"}},"outputId":"286645b2-2501-43c1-a520-a2740826f77d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['明日', 'は', 'マシン', '##ラー', '##ニング', 'の', '勉強', 'を', 'しよ', 'う', '.']"]},"metadata":{},"execution_count":9}],"source":["tokenizer.tokenize('明日はマシンラーニングの勉強をしよう.')"]},{"cell_type":"markdown","id":"40650fdf","metadata":{"id":"40650fdf"},"source":["｢##｣はサブワード分割の結果,最初の単語以外につく."]},{"cell_type":"code","execution_count":10,"id":"10a6ed06","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10a6ed06","executionInfo":{"status":"ok","timestamp":1660558446517,"user_tz":-540,"elapsed":1034,"user":{"displayName":"a kaya","userId":"07654136242285001252"}},"outputId":"e95f1c57-65ac-496e-b5e5-d901ce8e7e1b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['機械', '学習', 'を', '中国', '語', 'に', 'する', 'と', '机', '器', '学', '[UNK]', 'だ', '.']"]},"metadata":{},"execution_count":10}],"source":["tokenizer.tokenize('機械学習を中国語にすると机器学习だ.')"]},{"cell_type":"markdown","id":"bffb2ce7","metadata":{"id":"bffb2ce7"},"source":["习が未知語[UNK]トークンに変換されている."]},{"cell_type":"code","execution_count":12,"id":"bf17afa0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bf17afa0","executionInfo":{"status":"ok","timestamp":1660558460788,"user_tz":-540,"elapsed":750,"user":{"displayName":"a kaya","userId":"07654136242285001252"}},"outputId":"61f88adc-ba17-49a2-acad-b44b9e2762da"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 11475, 9, 1757, 1882, 2762, 5, 8192, 11, 2132, 205, 143, 3]\n"]}],"source":["#文章を符号化(ID化)するには encode()を使う.\n","input_ids = tokenizer.encode('明日は自然言語処理の勉強をしよう.')\n","print(input_ids)\n"]},{"cell_type":"markdown","id":"c9611097","metadata":{"id":"c9611097"},"source":["encode()は,  \n","- トークン列の先頭に[CLS]  \n","- 末尾に[SEP]  \n","を自動で追加する.\n"]},{"cell_type":"code","execution_count":13,"id":"110922f6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"110922f6","executionInfo":{"status":"ok","timestamp":1660558463182,"user_tz":-540,"elapsed":5,"user":{"displayName":"a kaya","userId":"07654136242285001252"}},"outputId":"d4b97eac-845d-4956-8976-663985f5194e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]', '明日', 'は', '自然', '言語', '処理', 'の', '勉強', 'を', 'しよ', 'う', '.', '[SEP]']"]},"metadata":{},"execution_count":13}],"source":["# ID ー> トークン は convert_ids_to_tokens()\n","tokenizer.convert_ids_to_tokens(input_ids)\n"]},{"cell_type":"code","execution_count":null,"id":"eb8cc75e","metadata":{"id":"eb8cc75e","outputId":"7ba86547-16fd-40f3-82ac-089f6d0e111c"},"outputs":[{"name":"stdout","output_type":"stream","text":["# encoding:\n","{'input_ids': [2, 11475, 5, 11385, 9, 16577, 75, 143, 3, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}\n","# tokens:\n","['[CLS]', '明日', 'の', '天気', 'は', '晴れ', 'だ', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n"]}],"source":["#BERTを利用するためにトークン列の長さ(系列長)を同じに揃える\n","#系列長が短ければ特殊トークン[PAD]を末尾に足す\n","#ながければ末尾トークンを削る\n","#[PAD]部分は処理に関係ないので,\n","#関係ある部分のみを表すattenntion_maskを用意しておく\n","\n","# tokenizerで指定した系列帳に揃えられたidやmaskの辞書が手に入る\n","# max_length : 系列長\n","# padding='max_length': 足りなかったら12まで[PAD]を足す\n","# truncation: 多かったら削る\n","\n","text = '明日の天気は晴れだ.'\n","encoding = tokenizer(\n","    text, max_length=12, padding='max_length', truncation=True\n",")\n","print('# encoding:')\n","print(encoding)\n","\n","tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'])\n","print('# tokens:')\n","print(tokens)"]},{"cell_type":"code","execution_count":null,"id":"eb4e2d51","metadata":{"id":"eb4e2d51","outputId":"50f0f4e6-d66a-4704-81c1-b7ff4eb997b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["# encoding:\n","{'input_ids': [2, 11475, 5, 11385, 9, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n","# tokens:\n","['[CLS]', '明日', 'の', '天気', 'は', '[SEP]']\n"]}],"source":["#系列長を短くしてみる\n","encoding = tokenizer(\n","    text, max_length=6, padding='max_length', truncation=True\n",")\n","print('# encoding:')\n","print(encoding)\n","\n","tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'])\n","print('# tokens:')\n","print(tokens)"]},{"cell_type":"code","execution_count":null,"id":"db6b2750","metadata":{"id":"db6b2750","outputId":"d850a95d-9e1b-4ba0-c08a-fdc22adc314d"},"outputs":[{"name":"stdout","output_type":"stream","text":["# encoding:\n","{'input_ids': [2, 11475, 5, 11385, 9, 16577, 75, 143, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","# tokens:\n","['[CLS]', '明日', 'の', '天気', 'は', '晴れ', 'だ', '.', '[SEP]']\n"]}],"source":["#truncationをFalseにしてみる\n","encoding = tokenizer(\n","    text, max_length=6, padding='max_length', truncation=False\n",")\n","print('# encoding:')\n","print(encoding)\n","\n","tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'])\n","print('# tokens:')\n","print(tokens)"]},{"cell_type":"code","execution_count":null,"id":"dbc5e6e9","metadata":{"id":"dbc5e6e9","outputId":"12fa0e46-d460-4494-8ce2-2f5a332df53e"},"outputs":[{"name":"stdout","output_type":"stream","text":["# encoding:\n","{'input_ids': tensor([[    2, 11475,     5, 11385,     9, 16577,    75,   143,     3,     0],\n","        [    2,  6311,    14,  1132,     7, 16084,   332,    58,    10,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"]}],"source":["#復数の文章をリストで渡せる\n","text_list = [ '明日の天気は晴れだ.'\n","             ,'パソコンが急に動かなくなった.' ]\n","\n","#それぞれリストが返ってくる\n","# padding=longest  で最も長い文章が系列長になる\n","\n","# BERTに入力する場合は数値配列はPyTorchの多次元配列を扱うための型\n","# torch.Tensorに変換する必要がある\n","# return_tensors='pt'でテンソルとして出力されそのまま入力可能\n","encoding = tokenizer( text_list\n","                     , max_length = 10\n","                     , padding='max_length'\n","                     , truncation=True\n","                     , return_tensors='pt'\n",")\n","print('# encoding:')\n","print(encoding)"]},{"cell_type":"code","execution_count":4,"id":"6e34857f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6e34857f","executionInfo":{"status":"ok","timestamp":1660557379598,"user_tz":-540,"elapsed":4636,"user":{"displayName":"a kaya","userId":"07654136242285001252"}},"outputId":"ac659ada-0e66-4657-d385-689a3de0c953"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["BertConfig {\n","  \"_name_or_path\": \"cl-tohoku/bert-base-japanese-whole-word-masking\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n","  \"transformers_version\": \"4.21.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n"]}],"source":["#符号化(トークン化→ID化)されたデータをBERTに入力する\n","#モデルのロード\n","model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n","bert = BertModel.from_pretrained(model_name)\n","\n","torch.device('mps')\n","\n","#BERTをGPUに載せる\n","bert = bert.cuda()\n","\n","#モデルの概要\n","print(bert.config)"]},{"cell_type":"code","execution_count":17,"id":"ac6e9cb8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ac6e9cb8","executionInfo":{"status":"ok","timestamp":1660558763226,"user_tz":-540,"elapsed":4,"user":{"displayName":"a kaya","userId":"07654136242285001252"}},"outputId":"13daa38b-c7b2-4914-b277-5e31ad93d250"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 32, 768])\n"]}],"source":["text_list = [ '明日は自然言語処理の勉強をしよう.'\n","            , '明日はマシーンラーニングの勉強をしよう.']\n","\n","encoding = tokenizer(  text_list\n","                     , max_length=32\n","                     , padding='max_length'\n","                     , truncation=True\n","                     , return_tensors='pt'\n",")\n","\n","#データをGPUに載せる\n","encoding = {k:v.cuda() for k, v in encoding.items()}\n","\n","# BERTでの処理処理 \n","# ｢**｣はencodingの中身を展開して入力\n","output = bert(**encoding) #それぞれの入力は2次元のtorch.Tensor\n","\n","###\n","# 記述としては以下と同じ\n","output = bert(  input_ids = encoding['input_ids']\n","              , attention_mask=encoding['attention_mask']\n","              , token_type_ids=encoding['token_type_ids']\n",")\n","###\n","\n","\n","# 最終層の出力(いわゆるモデルのモデルのOutput)\n","last_hidden_state = output.last_hidden_state\n","\n","#テンソルのサイズ\n","# 左から順にパッチサイズ2, 系列長32, 隠れ状態の次元768\n","print(last_hidden_state.size())"]},{"cell_type":"code","source":[""],"metadata":{"id":"pVWkAFkD_chn"},"id":"pVWkAFkD_chn","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"tQuw5USnAdMf"},"id":"tQuw5USnAdMf"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"colab":{"name":"ch4.ipynb","provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"a5dd80beb9b24b0fa03fdef858937a9c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99e26d43f47b4573bcf69c61b05cb8ca","IPY_MODEL_25b08c8b80cc4ab09beaef6ea85a6c50","IPY_MODEL_00924c4df9c64a6098012fc8d2c875d3"],"layout":"IPY_MODEL_62870f7f045c46ebaed551effe69e22a"}},"99e26d43f47b4573bcf69c61b05cb8ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6093022ac621423bbcf06beb413c3761","placeholder":"​","style":"IPY_MODEL_42a16b06b0154b42b7c4d00345e9cc33","value":"Downloading vocab.txt: 100%"}},"25b08c8b80cc4ab09beaef6ea85a6c50":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fb646e2ef5740a5b337590a8779b697","max":257706,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e2f916054d140e288a8ebf921cea1a2","value":257706}},"00924c4df9c64a6098012fc8d2c875d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f453b394e6884ee2bd3e79bf21f66d2e","placeholder":"​","style":"IPY_MODEL_d9484351b4af4d10b7eb558461a1edb9","value":" 252k/252k [00:00&lt;00:00, 287kB/s]"}},"62870f7f045c46ebaed551effe69e22a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6093022ac621423bbcf06beb413c3761":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42a16b06b0154b42b7c4d00345e9cc33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fb646e2ef5740a5b337590a8779b697":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e2f916054d140e288a8ebf921cea1a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f453b394e6884ee2bd3e79bf21f66d2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9484351b4af4d10b7eb558461a1edb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e96e608c4f9420ea89c64c8ab526542":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eaecc0960283409999a8b2346317884b","IPY_MODEL_6fec5d77d9ff43e5bc66e6d4414d20e7","IPY_MODEL_16f8e28a7de74322a3700c0b4e152c23"],"layout":"IPY_MODEL_42dd4e35bff94ca7af5605145ab0302e"}},"eaecc0960283409999a8b2346317884b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99117651d5b14c4281697752cd5bf802","placeholder":"​","style":"IPY_MODEL_91a81747e8514089b9d436144b9dfce2","value":"Downloading tokenizer_config.json: 100%"}},"6fec5d77d9ff43e5bc66e6d4414d20e7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0544859bde5c4d0e85a9fd88ca6c0149","max":110,"min":0,"orientation":"horizontal","style":"IPY_MODEL_600668237b3e4112904f09cb783d76dd","value":110}},"16f8e28a7de74322a3700c0b4e152c23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c88616557ffe45c194c25682fb763e87","placeholder":"​","style":"IPY_MODEL_d11a78602be6413c8d3f1ae4e7177a2c","value":" 110/110 [00:00&lt;00:00, 3.34kB/s]"}},"42dd4e35bff94ca7af5605145ab0302e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99117651d5b14c4281697752cd5bf802":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91a81747e8514089b9d436144b9dfce2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0544859bde5c4d0e85a9fd88ca6c0149":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"600668237b3e4112904f09cb783d76dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c88616557ffe45c194c25682fb763e87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d11a78602be6413c8d3f1ae4e7177a2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}